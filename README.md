# Multi-Agent News Intelligence System

![Python](https://img.shields.io/badge/Python-3.11-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)
![Google Cloud](https://img.shields.io/badge/Google%20Cloud-GCP-orange.svg)

AI-powered news aggregation system with semantic search and trending analysis.

üåê **Check it out here**: [news-intelligence-api-1062778057195.us-central1.run.app](https://news-intelligence-api-1062778057195.us-central1.run.app/)

---

## About The Project

This system automatically collects, processes, and organizes news from multiple sources. Instead of browsing different news websites, users can ask natural language questions and get AI-generated summaries with proper citations.

The project demonstrates a multi-agent architecture where specialized components handle different tasks - from data collection to semantic search to report generation.

### Built With

- [FastAPI](https://fastapi.tiangolo.com/) - Modern web framework for APIs
- [FAISS](https://faiss.ai/) - Efficient similarity search and clustering
- [Google Gemini](https://deepmind.google/technologies/gemini/) - Large language model for text generation
- [Sentence Transformers](https://www.sbert.net/) - Text embeddings for semantic search
- [Google Cloud Platform](https://cloud.google.com/) - Cloud infrastructure and deployment

---

## Features

- **Semantic Search**: Ask questions like "What's happening with AI these days?" and get relevant articles
- **Trending Analysis**: See what's trending across Politics, Technology, Sports, Health, Crime, Entertainment
- **Regional Focus**: Separate analysis for India vs Global news
- **Daily Automation**: Fresh news collected and processed every day via GCP schedulers
- **AI Summaries**: Coherent reports generated from multiple sources with citations

---

## How It Works

The system uses a multi-agent architecture with specialized components:

**SearchAgent**: Handles semantic search using sentence transformers and FAISS indexing  
**ReportingAgent**: Generates summaries from multiple sources  
**Main Orchestrator**: Coordinates workflows and manages API requests  
**Data Pipeline**: Automated collection and processing (runs nightly on GCP)

### Daily Workflow

1. **2:00 AM UTC**: NewsScraper job collects ~600 articles from news APIs
2. **3:00 AM UTC**: NewsDataProcessor job processes articles, builds search indexes, generates trending summaries  
3. **All Day**: API serves real-time queries through web interface

---

## Architecture

### Multi-Agent Design

The system separates concerns into specialized agents rather than using a monolithic approach:

- **Maintainability**: Each agent has a single responsibility
- **Scalability**: Agents can be scaled independently  
- **Reliability**: If one agent fails, others continue working
- **Extensibility**: New agents can be added without modifying existing ones

### Technology Choices

**FastAPI**: Async performance for real-time queries  
**FAISS**: Efficient semantic search across thousands of articles  
**Sentence Transformers**: Lightweight embeddings for news similarity  
**GCP Cloud Run**: Auto-scaling deployment with scheduled jobs  

---

## Project Structure

```
‚îú‚îÄ‚îÄ NewsAgent/                 # API service and agents
‚îÇ   ‚îú‚îÄ‚îÄ agents/               # Specialized AI agents  
‚îÇ   ‚îú‚îÄ‚îÄ app/                  # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh            # Deployment script
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile           # Container configuration
‚îî‚îÄ‚îÄ NewsAgentData/            # Data pipeline services
    ‚îú‚îÄ‚îÄ NewsScraper/         # Data collection job (Dockerfile included)
    ‚îî‚îÄ‚îÄ NewsDataProcessor/   # Data processing job (Dockerfile included)
```

---

## Usage

Visit the [deployed system](https://news-intelligence-api-1062778057195.us-central1.run.app/) or use the API endpoints:

### Search for News
```bash
curl -X POST "https://news-intelligence-api-1062778057195.us-central1.run.app/api/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "artificial intelligence developments", "max_results": 5}'
```

### Get Trending Topics  
```bash
# All trending news
curl "https://news-intelligence-api-1062778057195.us-central1.run.app/api/trending"

# India technology news
curl "https://news-intelligence-api-1062778057195.us-central1.run.app/api/trending/India/technology"
```

---

## Running Locally

The system requires multiple components and external APIs. For local development:

### Prerequisites
- Python 3.11+
- Docker
- Google Cloud Platform account
- [newsdata.io](https://newsdata.io/) API key (free tier available)
- Google Gemini API key

### Setup Overview
1. **Data Collection**: Build and run NewsScraper job with newsdata.io API key
2. **Data Processing**: Build and run NewsDataProcessor job to generate indexes
3. **API Service**: Deploy NewsAgent with Gemini API key using `deploy.sh`

*Note: Full setup involves configuring multiple Docker containers and cloud services. The deployed version above is ready to use.*

---

## Deployment

The system is deployed on Google Cloud Platform using:

- **Cloud Run**: Auto-scaling API service
- **Cloud Scheduler**: Automated data pipeline jobs  
- **Cloud Storage**: Centralized data and index storage

Each component (NewsScraper, NewsDataProcessor, NewsAgent) has its own Dockerfile for containerized deployment.

---

## Contributing

Contributions are welcome! Feel free to:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## License

Distributed under the MIT License. See `LICENSE` for more information.

---

## Contact
- LinkedIn: [Mohit Gupta](https://www.linkedin.com/in/mohit-gupta-a81488221)
- GitHub: [@mohitgupta00](https://github.com/mohitgupta00)
- Project Link: [https://github.com/mohitgupta00/multi-agent-news-intelligence](https://github.com/mohitgupta00/multi-agent-news-intelligence)